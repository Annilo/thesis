{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ad350b-224b-4bfa-94bf-c98a391060e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.rm(\"dbfs:/user/hive/warehouse/iws_state\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad7fa66b-07c2-4305-94a8-bd8fc1a7044a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "At the moment there are many variables in the table, maybe it would make sense to restructure the table somewhat. Also at the moment: do not need children_labels or children_id. What if this wasn't in one table, but two tables: iws_model and iws_children where iws_model had children id which matched the id-s in children table, so it would be one to many. This would create many rows which would be duplicates besides the id (or perhaps many-many). This would make updating the structure of the table more simple? If there is a need to change the structure of the model anyway. The same goes with having id-s as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d72cb05f-6655-4be4-97e7-3f07f5d8248f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE iws_model AS\n",
    "SELECT \"root\" AS id, \"-\" AS label, array(\"A\") AS children_labels, array(\"root-A\") AS children_id, \n",
    "    array(\n",
    "        struct(\"root-A\" AS node_id, \"A\" AS label, 1 as level, array() as events_between),\n",
    "        struct(\"root-A-B\" AS node_id, \"B\" AS label, 2 as level, array(\"A\") as events_between),\n",
    "        struct(\"root-A-B-X\" AS node_id, \"X\" AS label, 3 as level, array(\"A\",\"B\") as events_between), \n",
    "        struct(\"root-A-B-D\" AS node_id, \"D\" AS label, 3 as level, array(\"A\",\"B\") as events_between)\n",
    "    ) AS nth_level_children\n",
    "UNION ALL \n",
    "SELECT \"root-A\", \"A\", array(\"B\"), array(\"root-A-B\"), \n",
    "    array(\n",
    "        struct(\"root-A-B\" AS node_id, \"B\" AS label, 2 as level, array() as events_between),\n",
    "        struct(\"root-A-B-X\" AS node_id, \"X\" AS label, 3 as level, array(\"B\") as events_between),\n",
    "        struct(\"root-A-B-D\" AS node_id, \"D\" AS label, 3 as level, array(\"B\") as events_between),\n",
    "        struct(\"root-A-B-D-C\" AS node_id, \"C\" AS label, 4 as level, array(\"B\",\"D\") as events_between)\n",
    "    )\n",
    "UNION ALL \n",
    "SELECT \"root-A-B\", \"B\", array(\"X\", \"D\"), array(\"root-A-B-X\", \"root-A-B-D\"), \n",
    "    array(\n",
    "        struct(\"root-A-B-X\" AS node_id, \"X\" AS label, 3 as level, array() as events_between), -- \"A-B-C\" now \"A-B-X\"\n",
    "        struct(\"root-A-B-D\" AS node_id, \"D\" AS label, 3 as level, array() as events_between),\n",
    "        struct(\"root-A-B-D-C\" AS node_id, \"C\" AS label, 4 as level, array(\"D\") as events_between)\n",
    "    )\n",
    "UNION ALL \n",
    "SELECT \"root-A-B-X\", \"X\", array(), array(),\n",
    "    array()\n",
    "UNION ALL \n",
    "SELECT \"root-A-B-D\", \"D\", array(\"C\"), array(\"root-A-B-D-C\"), \n",
    "    array(\n",
    "        struct(\"root-A-B-D-C\" AS node_id, \"C\" AS label, 4 as level, array() as events_between),\n",
    "        struct(\"root-A-B-D-C-D\" AS node_id, \"D\" AS label, 5 as level, array(\"C\") as events_between),\n",
    "        struct(\"root-A-B-D-C-C\" AS node_id, \"C\" AS label, 5 as level, array(\"C\") as events_between)\n",
    "    )\n",
    "UNION ALL \n",
    "SELECT \"root-A-B-D-C\", \"C\", array(\"D\", \"C\"), array(\"root-A-B-D-C-D\", \"root-A-B-D-C-C\"), \n",
    "    array(\n",
    "        struct(\"root-A-B-D-C-D\" AS node_id, \"D\" AS label, 5 as level, array() as events_between),\n",
    "        struct(\"root-A-B-D-C-C\" AS node_id, \"C\" AS label, 5 as level, array() as events_between)\n",
    "    )\n",
    "UNION ALL \n",
    "SELECT \"root-A-B-D-C-D\", \"D\", array(), array(), array()\n",
    "UNION ALL \n",
    "SELECT \"root-A-B-D-C-C\", \"C\", array(), array(), array();\n",
    "\n",
    "CREATE OR REPLACE TABLE iws_event \n",
    "SELECT \"A\" event, CURRENT_TIMESTAMP() ts, \"trace_id_0\" trace_id,;\n",
    "\n",
    "CREATE OR REPLACE TABLE iws_state\n",
    "(trace_id STRING, ts TIMESTAMP, current_node STRING,current_id STRING,cost_of_alignment INTEGER,previous_events STRING, trace STRING, execution_sequence STRING,event_level INTEGER,current_event_level INTEGER,current_node_level INTEGER);\n",
    "--event level to filter out the latest alignments later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c98a794-b5af-43fb-be1c-193203e70b83",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  explode(\n",
    "    transform(\n",
    "      filter(nth_level_children, x -> x.label = 'C'),\n",
    "      x -> struct(x.node_id AS node_id, concat(repeat(\">>\", 7 - x.level), \"-\", \"event\") AS description)\n",
    "    )\n",
    "  ) AS nodes_with_label_C\n",
    "FROM iws_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38905d9b-596d-4856-9a8a-c59737d41a16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "activities = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "trace_id_lower = 0\n",
    "trace_id_upper = 9\n",
    "\n",
    "def insert_event(event=None, trace_id=None):\n",
    "    if not event:\n",
    "        event = random.choice(activities)\n",
    "    if not trace_id:\n",
    "        trace_id = 0 #random.randint(trace_id_lower, trace_id_upper)\n",
    "    spark.sql(f\"INSERT INTO iws_event SELECT '{event}', CURRENT_TIMESTAMP(), 'trace_id_{trace_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "effece77-812a-44bb-8d04-506d33f01dcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97acdc3a-11d6-43f3-a866-ca05af9e69d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F \n",
    "from time import sleep\n",
    "event_df = spark.readStream.table(\"iws_event\").withWatermark(\"ts\", \"30 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e242c49d-397b-4967-bae1-48fab93463b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "event_df.createOrReplaceTempView(\"events\")\n",
    "#maybe add level already to events so dont have to take substring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa090f3-3b2a-4089-b268-5ea3fa02a665",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "CREATE OR REPLACE TEMP VIEW latest_state AS \n",
    "SELECT trace_id, ts, current_node, current_id, cost_of_alignment,true_previous_events as previous_events,trace,execution_sequence,event_level, max_event_level as current_event_level,current_node_level FROM (\n",
    "SELECT *, row_number() OVER (PARTITION BY trace_id,current_id order by event_level desc, cost_of_alignment asc) rn,\n",
    "max(event_level) OVER (PARTITION BY trace_id) AS max_event_level, max(previous_events) OVER (PARTITION BY trace_id) as true_previous_events FROM iws_state\n",
    ") WHERE rn = 1 --and event_level > current_event_level -2\n",
    "--need to only get the values where when the node_id is the same, then the one with the highest event level is saved\n",
    "-- Trace needs to be like this since we are possibly using past events (which are not updated) in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "887ac5cf-9869-4d87-a91b-5fcc08697ace",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fae842ab7f0>"
     ]
    }
   ],
   "source": [
    "#if looking at older events, cost should be difference in event levels also number of skips >> between is same number\n",
    "#TODO FIX IF EVENT IS FIRST COMING IN (fix with adding root row automatically)\n",
    "#current level -> used to track what event the state is from if the state is used in the future\n",
    "#event level -> used to track the current event level (how many events there have been)\n",
    "#current_node_level -> used to track what level the node is, used in calculation\n",
    "#model moves in trace(sigma), log moves in execution sequence (pi) \n",
    "#right now log and model moves are done without any difference really\n",
    "spark.sql(\"\"\"\n",
    "SELECT trace_id, ts, exploded.*, previous_events\n",
    "FROM (\n",
    "    SELECT \n",
    "      e.trace_id, \n",
    "      e.ts,\n",
    "      concat(e.previous_events,e.event) as previous_events,\n",
    "      CASE \n",
    "        WHEN array_contains(transform(m.nth_level_children, x -> x.label), e.event) THEN\n",
    "          transform(\n",
    "            filter(m.nth_level_children, x -> x.label LIKE e.event),\n",
    "            x -> struct(e.event as current_node, x.node_id as current_id, e.cost_of_alignment + abs(x.level - current_node_level-1) + current_event_level - event_level as cost_of_alignment, CASE WHEN current_event_level != event_level THEN concat(coalesce(trace, \"root\"),substring(previous_events,event_level+1,current_event_level+1), repeat(\">>\", abs(x.level - current_node_level-1)), e.event) ELSE concat(coalesce(trace,\"root\"),repeat(\">>\",abs(x.level - current_node_level-1)),e.event) END as trace,CONCAT(execution_sequence,repeat(\">>\", abs(current_event_level - event_level)), coalesce(CONCAT_WS('', x.events_between)),e.event) as execution_sequence, current_event_level+1 as event_level, current_event_level + 1 as current_event_level,x.level as current_node_level)\n",
    "          )\n",
    "        ELSE\n",
    "          array(struct(e.current_node as current_node, m.id as current_id, e.cost_of_alignment + e.current_event_level - e.event_level + 1 as cost_of_alignment, concat(trace,substring(previous_events,event_level+1,current_event_level+1), e.event) as trace, concat(execution_sequence, repeat(\">>\", current_event_level - event_level), \">>\")as execution_sequence, e.current_event_level + 1 as event_level, current_event_level + 1 as current_event_level, current_node_level))\n",
    "      END AS exploded_struct\n",
    "    FROM \n",
    "      (SELECT e.*, COALESCE(r.current_node, \"-\") as current_node, COALESCE(r.current_id, \"root\") as current_id, coalesce(cost_of_alignment, 0) as cost_of_alignment, coalesce(r.previous_events,\"\") as previous_events , coalesce(trace,\"\") as trace, coalesce(execution_sequence,\"\") as execution_sequence, coalesce(event_level, 0) as event_level, coalesce(current_event_level, 0) as current_event_level,coalesce(current_node_level,0) as current_node_level FROM events e LEFT JOIN latest_state r ON e.trace_id = r.trace_id) e \n",
    "    JOIN iws_model m ON e.current_id = m.id\n",
    ") \n",
    "LATERAL VIEW explode(exploded_struct) t AS exploded\n",
    "\"\"\").writeStream.format(\"delta\").outputMode(\"append\").option(\"checkpointLocation\",\"/tmp/delta/state_append_32/\").toTable(\"iws_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d325c742-cd32-459e-ba26-1fbc30ad4177",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>trace_id</th><th>ts</th><th>current_node</th><th>current_id</th><th>cost_of_alignment</th><th>previous_events</th><th>trace</th><th>execution_sequence</th><th>event_level</th><th>current_event_level</th><th>current_node_level</th></tr></thead><tbody><tr><td>trace_id_6</td><td>2024-04-11T19:34:31.332+0000</td><td>A</td><td>root-A</td><td>2</td><td>AXFDXC</td><td>AXF</td><td>A>>>></td><td>3</td><td>6</td><td>1</td></tr><tr><td>trace_id_6</td><td>2024-04-11T19:35:05.516+0000</td><td>D</td><td>root-A-B-D</td><td>4</td><td>AXFDXC</td><td>AXF>>DX</td><td>A>>>>BD>></td><td>5</td><td>6</td><td>3</td></tr><tr><td>trace_id_6</td><td>2024-04-11T19:35:34.522+0000</td><td>C</td><td>root-A-B-D-C</td><td>4</td><td>AXFDXC</td><td>AXF>>DXC</td><td>A>>>>BD>>C</td><td>6</td><td>6</td><td>4</td></tr><tr><td>trace_id_6</td><td>2024-04-11T19:35:34.522+0000</td><td>C</td><td>root-A-B-D-C-C</td><td>5</td><td>AXFDXC</td><td>AXF>>DX>>C</td><td>A>>>>BD>>CC</td><td>6</td><td>6</td><td>5</td></tr><tr><td>trace_id_6</td><td>2024-04-11T19:35:34.522+0000</td><td>X</td><td>root-A-B-X</td><td>5</td><td>AXFDXC</td><td>A>>XFDXC</td><td>ABX>>>>>>>></td><td>6</td><td>6</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "trace_id_6",
         "2024-04-11T19:34:31.332+0000",
         "A",
         "root-A",
         2,
         "AXFDXC",
         "AXF",
         "A>>>>",
         3,
         6,
         1
        ],
        [
         "trace_id_6",
         "2024-04-11T19:35:05.516+0000",
         "D",
         "root-A-B-D",
         4,
         "AXFDXC",
         "AXF>>DX",
         "A>>>>BD>>",
         5,
         6,
         3
        ],
        [
         "trace_id_6",
         "2024-04-11T19:35:34.522+0000",
         "C",
         "root-A-B-D-C",
         4,
         "AXFDXC",
         "AXF>>DXC",
         "A>>>>BD>>C",
         6,
         6,
         4
        ],
        [
         "trace_id_6",
         "2024-04-11T19:35:34.522+0000",
         "C",
         "root-A-B-D-C-C",
         5,
         "AXFDXC",
         "AXF>>DX>>C",
         "A>>>>BD>>CC",
         6,
         6,
         5
        ],
        [
         "trace_id_6",
         "2024-04-11T19:35:34.522+0000",
         "X",
         "root-A-B-X",
         5,
         "AXFDXC",
         "A>>XFDXC",
         "ABX>>>>>>>>",
         6,
         6,
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "trace_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ts",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "current_node",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "current_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cost_of_alignment",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "previous_events",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "trace",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "execution_sequence",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_level",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "current_event_level",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "current_node_level",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM latest_state where trace_id = \"trace_id_6\"\n",
    "-- vaata mis state on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53520f74-4f1b-4827-af69-b2aac2d673bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * from iws_state ---where trace_id = \"trace_id_2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf208c8-bc7b-459d-96cf-32e22626cae9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "insert_event(\"A\",\"6\")\n",
    "sleep(3)\n",
    "insert_event(\"X\",\"6\")\n",
    "sleep(5)\n",
    "insert_event(\"F\",\"6\")\n",
    "sleep(5)\n",
    "insert_event(\"D\",\"6\")\n",
    "sleep(5)\n",
    "insert_event(\"X\",\"6\")\n",
    "sleep(5)\n",
    "insert_event(\"C\",\"6\")\n",
    "#sleep(2)\n",
    "#for i in range(5):\n",
    "#    insert_event(trace_id = \"5\")\n",
    "    #sleep(2)\n",
    "# lisa uus event. Vaata uuesti mis state on (ülemine cell)\n",
    "# võid katsetada lisada suvalist eventi vahepeal, nt X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da461519-91d6-4c7b-8205-12cd71cefe52",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#näited funktsioonide tööpõhimõtetest arusaamiseks\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "data = [\n",
    "    (1, 'Event1', True, False),\n",
    "    (2, 'Event2', True, True),\n",
    "    (3, 'Event3', False, True)\n",
    "]\n",
    "columns = ['ID', 'Event', 'ConditionA', 'ConditionB']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "df.createOrReplaceTempView(\"events\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ID, Event, \n",
    "       explode(arrays_zip(\n",
    "         array(CASE WHEN ConditionA THEN 'A' ELSE NULL END, CASE WHEN ConditionB THEN 'B' ELSE NULL END),\n",
    "         array(CASE WHEN ConditionA THEN 'Condition A Met' ELSE NULL END, CASE WHEN ConditionB THEN 'Condition B Met' ELSE NULL END)\n",
    "       )) as conditions\n",
    "FROM events\n",
    "WHERE ConditionA OR ConditionB\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)\n",
    "\n",
    "result = result.selectExpr(\"ID\", \"Event\", \"conditions['0'] as Condition\", \"conditions['1'] as Label\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c24c9921-5a75-4ab4-aab3-05ccbe85435b",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, when, array, explode\n",
    "\n",
    "data = [(\"A\",), (\"B\",)]\n",
    "schema = [\"condition\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()\n",
    "\n",
    "df.createOrReplaceTempView(\"conditions_table\")\n",
    "\n",
    "result_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    exploded.item AS item,\n",
    "    exploded.value AS value\n",
    "FROM (\n",
    "    SELECT explode(\n",
    "        CASE \n",
    "            WHEN condition = 'A' THEN array(struct('A' AS item, 5 AS value))\n",
    "            WHEN condition = 'B' THEN array(struct('D' AS item, 6 AS value), struct('C' AS item, 7 AS value), struct('F' AS item, 8 AS value))\n",
    "            ELSE array() -- Handle other conditions or default case\n",
    "        END\n",
    "    ) AS exploded\n",
    "    FROM conditions_table\n",
    ") AS t\n",
    "\"\"\")\n",
    "\n",
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3189399297484317,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "agnes_example_adding_model_moves",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
